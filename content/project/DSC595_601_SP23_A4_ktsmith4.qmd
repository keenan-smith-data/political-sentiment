---
title: "Political Sentiment NLP"
author: "Keenan Smith"
format:
  revealjs:
    theme: serif
    logo: ncstate-type-2x2-red.png
    footer: Political_Sentiment_Capstone_Smith_Keenan 
    width: 1920
    height: 1080
    embed-resources: true
    self-contained-math: true
---

# Overview

:::: {.columns}
::: {.column width="50%"}

-   Introduction
    -   Research Question, Political Ideology, NLP
-   Methods
    -   The Data
    -   Programming Language
    -   Data Collection

:::

::: {.column width="50%"}

-   Results
    -   EDA
    -   Model Results
-   Further Work
-   Questions

:::
::::

## Research Question

A **Data Science** Project that examines the question *"Does Political Speech indicate classical right-left political bias?"*

:::: {.columns}
::: {.column width="55%"}

- The Corpus consists of Ideologically Identified Sources
  - Primarily U.S. Think Tanks
    - Specifically Chosen for Bias
  - Data are Scraped from the Web
  - These Data are in English
- Classical Machine Learning Techniques are used for Classification
  - Transformers (The tech behind GPT) are goals for the future
- Source Code is Located on Github [Github](https://github.com/keenan-smith-data/political-sentiment)

:::

::: {.column width="45%"}

**Why?**

- We live in a politically charged and active time in the United States
- I like history, politics, and Natural Language
- How we communicate is meaningful and important
- The US Supreme Court uses Originalism and Textualism in their decisions

:::
::::

::: {.notes}
My interests are all the things you are not supposed to talk about at Thanksgiving
Transformers are the current highest form for NLP modeling but require much more computing power
:::

## Political Ideology

"Ideologies have for different individuals, different degrees of appeal. A matter that depends upon the individuals needs and the degree to which these needs are being satisfied or frustrated." (Adorno et al. 1950)

- The study of political ideology is vast and complex (Feldman 2013; Feldman, 2017; Jost, 2017)
  - Construction of political parties are equally complicated and vast (Mayer, 2018; Mudge, 2018)
- This project chooses intentionally to focus on a wide corpus of data from left and right
- Clustering of the Sources used shows this is a complicated topic
  - Further work should focus on this diversity and complexity
  
![Credit: Wikipedia 118th US Congress Makeup](images/118th_US_House_of_Representatives.png)

::: {.notes}
Speaker notes go here.
:::

## Natural Language Processing {.smaller}

"the application of computer science to the **analysis, synthesis, and comprehension"** of written and spoken language" (Oxford Dictionary)

:::: {.columns}
::: {.column width="55%"}

- Mixing Data Science and how we use Natural Language
- NLP use linguistic tools to build *features* out of langauge
- These features are then transformed into mathematical vectors in order to model
  - Tokens (units of language)
    - Characters, Words, n-grams, Sentences, Paragraphs
  - Term Frequency
  - Term Frequency Inverse Document Frequency (Tf-idf)
  - Embeddings (not used in this project)
  
:::

::: {.column width="45%"}
![Credit: Xoriant](images/nlp_picture.png)
:::
::::

- There are many other applications such as sentiment analysis and topic modeling to name a few

::: {.notes}
Speaker notes go here.
:::

# Methods

## The Data {.smaller}

:::: {.columns}
::: {.column width="65%"}
- Bias
  - Selected Data Sources on Availability of Data
  - Trimmed as much as reasonably practical from Large Sources
  - Stopwords chosen based on EDA and Early Models
    - Removed artifacts left behind from scrape
- Data Integrity
  - Data Scraped Straight Into SQL Database
  - Strict Type Adherence
  - Uniqueness of Links Checked through Final Corpus selection
  - No Text, No Input into DB

:::

::: {.column width="35%"}

- Metadata
  - Article Link `art_link` VARCHAR
  - Article Date `art_date` DATE
  - Article Author(s) `art_author` VARCHAR
  - Article Source `art_source` VARCHAR
  - Article Bias `art_bias` VARCHAR
- Data
  - Text VARCHAR

:::
::::

::: {.notes}
This needs some tables
:::

## Data Sample {.scrollable}

```{r}
sample_text <- tidytable::fread("sample_corpus.csv")
kableExtra::kbl(sample_text) |>
  kableExtra::kable_styling(bootstrap_options = "striped", font_size = 16)
```

::: {.notes}
Table of Sample Data
:::

## Process

![Technical Flow Chat](Flow Chart.drawio.png)

::: {.notes}
Speaker notes go here.
:::

# Results

## Data Source in Length of Text {.scrollable}

```{r}
source_count <- tidytable::fread("source_count_filtered.csv")
kableExtra::kbl(source_count) |>
  kableExtra::kable_styling(bootstrap_options = "striped", font_size = 28)
```


## Exploratory Data Analysis {.smaller}

![Histogram Length Text by Bias](images/corpus_histogram_filtered_bias.png)

::: {.notes}
Speaker notes go here.
:::

## Exploratory Data Analysis {.smaller}

![Histogram Length Text by Bias](images/corpus_histogram_filtered_source.png)

## Bigram Wordclouds

:::: {.columns}
::: {.column width="50%"}

![](images/left_freq_wordcloud_bigram.png)

:::

::: {.column width="50%"}

![](images/right_freq_bigram_wordcloud.png)

:::
::::

## Model Results  {.scrollable}

::: {.panel-tabset}

### Tab A

:::: {.columns}
::: {.column width="55%"}

- 3000 of the Most Frequent Bigrams Selected
  - Bigrams contain more information than Word Tokens
  - Early Modeling showed Bigrams had better results
- Regularized LASSO Regression Used so far

```{r}
lasso_test_metrics <- tidytable::fread("lasso_test_metrics.csv")
kableExtra::kbl(lasso_test_metrics) |>
  kableExtra::kable_styling(bootstrap_options = "striped", font_size = 28)
```

:::

::: {.column width="45%"}

![](images/variable_importance_plot.png)

:::
::::

### Tab B (ROC Curve)

![](images/roc_curve_lasso.png)

:::

::: {.notes}
Speaker notes go here.
:::

## Conclusion & Remarks

- Results appear to be promising
  - An Accuracy of 82% and ROC AUC of 90% is excellent for LASSO Regresssion
  - Results are Relatively Easy to Interpret
- The Dataset is Large but not Unwieldy for others to Utilize
- The R Packages Utilized are Manageable and Easy to Learn
- Scraping is Easy to Replicate but Hard to find good sources

# Questions
