---
title: "naivebayes NLP Modeling"
author: "Keenan Smith"
---

```{r}
#| output: false
#| label: Reading in initial Libraries
here::i_am("content/modeling/bigram_nlp_modeling_naivebayes_bow.qmd")
library(tidymodels)

library(parallel)
all_cores <- parallel::detectCores(logical = FALSE)
cl <- parallel::makePSOCKcluster(all_cores)
doParallel::registerDoParallel(cl)

sparse_bp <- hardhat::default_recipe_blueprint(composition = "dgCMatrix")

docid_to_bias <- function(df) {
  df |>
    tidytable::separate_wider_delim(doc_id, delim = "_", names = c("short_source", "pull_index", "source_bias"), cols_remove = TRUE) |>
    tidytable::select(-short_source, -pull_index)
}
```

```{r}
bigram_bow <- tidytable::fread(here::here("data", "model_data", "bow_bigram_df_4k.csv.gz"))

rownames(bigram_bow) <- bigram_bow$doc_id
```

# Getting Classification out of Doc ID

```{r}
bigram_bow <- docid_to_bias(bigram_bow)
```

# Data Split

```{r}
set.seed(2023)
bow_split <- initial_split(bigram_bow, strata = source_bias)

bigram_train <- training(bow_split)
bigram_test <- testing(bow_split)
bigram_folds <- vfold_cv(bigram_train)
```

# Engine

```{r}
library(discrim)
naivebayes_spec <- naive_Bayes() |>
  set_mode("classification") |>
  set_engine("naivebayes")
```

# Recipes

```{r}
text_rec <- recipe(source_bias ~ ., data = bigram_train)
```

# Workflows

```{r}
tune_wf <- workflow() |>
  add_recipe(text_rec) |>
  add_model(naivebayes_spec)
```

# Metric Set

```{r}
class_metrics <- metric_set(sens, spec, recall, precision, f_meas, accuracy, roc_auc, pr_auc)
```

# Hyperparameter Tuning

```{r}
tune_rs <- tune_grid(
  tune_wf,
  bigram_folds,
  metrics = class_metrics,
  control = control_resamples(save_pred = TRUE)
)

readr::write_rds(tune_rs, "model_results/tune_results_naivebayes_bow.rds", compress = "gz")
```

# Hyperparameter Metrics

```{r}
naivebayes_rs_metrics <- collect_metrics(tune_rs)
tidytable::fwrite(naivebayes_rs_metrics, here::here("content", "modeling", "model_results", "naivebayes_rs_metrics_bow_bigrams_4k.csv"))
naivebayes_rs_predictions <- collect_predictions(tune_rs)

naivebayes_rs_metrics
```

## Resample ROC Curves

```{r}
naivebayes_rs_predictions |>
  group_by(id) |>
  roc_curve(truth = source_bias, `.pred_left-wing`) |>
  autoplot() +
  labs(
    color = NULL,
    title = "ROC curve for Naive Bayes Predictions",
    subtitle = "Each resample fold is shown in a different color"
  )
ggsave("plots/cv_roc_naivebayes_bow.png")
```

# Fitting Model on Training Data

```{r}
fitted_naivebayes <- fit(tune_wf, bigram_train)
```

# Variable Importance Examination

## Variable Importance Plot

```{r}
library(vip)

vip_naivebayes <- fitted_naivebayes |>
  extract_fit_parsnip() |>
  vi()

vip_naivebayes |>
  slice_head(n = 20) |>
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

ggsave("plots/variable_importance_plot_naivebayes_bow.png")
```

```{r}
last_fit_naivebayes <- last_fit(final_naivebayes, bow_split)

naivebayes_metric <- last_fit_naivebayes |>
  collect_predictions() |>
  class_metrics(source_bias, estimate = .pred_class, `.pred_left-wing`)

tidytable::fwrite(naivebayes_metric, "model_results/naivebayes_test_metrics_bow.csv")

last_fit_naivebayes |>
  collect_predictions() |>
  roc_curve(source_bias, `.pred_left-wing`) |>
  autoplot()

ggsave("plots/roc_curve_naivebayes_bow.png")

last_fit_naivebayes |>
  collect_predictions() |>
  conf_mat(source_bias, .pred_class) |>
  autoplot(type = "heatmap")

ggsave("plots/confusion_matrix_naivebayes_bow.png")
```

