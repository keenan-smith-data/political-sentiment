---
title: "Sitemap Cleaning"
author: "Keenan Smith"
format: html
---

```{r}
#| label: Library Initiation

here::i_am("content/sitemap_links/sitemap_cleanup_linkchecker.qmd")
library(tidytable)
library(here)
library(googledrive)
library(stringr)
```

```{r}
#| label: Downloading Data from Google Drive
drive_auth(token = drive_token())
```

Only Run when needed to pull down from drive

```{r}
#| label: Downloading csv data off Google Drive
#| eval: false
links_raw <- drive_find(pattern = "links_raw")

raw_links_download <- function(drive_link) {
  drive_download(drive_link, path = here::here("data", drive_link))
}

purrr::map(.x = links_raw$name, raw_links_download)
```

Only needed until Drive is updated with new dataset

```{r}
#| label: Editing old Raw American Mind Links
#| eval: false
links_raw_am_mind <- fread(here("data", "links_raw_americanmindlinks.csv"), header = TRUE)
links_edited_am_mind <-
  links_raw_am_mind |>
    select(1:17)
fwrite(links_edited_am_mind, here("data", "links_raw_americanmindlinks.csv"))
```


```{r}
#| label: Pull Filenames and Files to List
files <- fs::dir_ls(here("data", "linkchecker"), regexp = "\\.csv$")

links_raw_test <- map(.x = files, .f = fread, header = TRUE, fill = TRUE)
```


```{r}
links_raw_linkcheck <- tidytable::bind_rows(links_raw_test)

filtered_linkcheck <- links_raw_linkcheck |>
  tidytable::filter(result == "200 OK") |>
  tidytable::distinct(url, .keep_all = TRUE) |>
  tidytable::select(parentname, result, infostring, url, size) |>
  tidytable::mutate(test_source = as.factor(case_when(
           stringr::str_detect(parentname, "americanmind.org") ~ "American Mind",
           stringr::str_detect(parentname, "claremontreviewofbooks.com") ~ "Claremont Institute",
           stringr::str_detect(parentname, "jacobin.com") ~ "Jacobin",
           stringr::str_detect(parentname, "commonwealthfund.org") ~ "Commonwealth Fund",
           stringr::str_detect(parentname, "epi.org") ~ "EPI",
           stringr::str_detect(parentname, "heritage.org") ~ "Heritage Foundation",
           stringr::str_detect(parentname, "nationalreview.com") ~ "National Review",
           stringr::str_detect(parentname, "opensocietyfoundations.org") ~ "Open Society Foundations",
           stringr::str_detect(parentname, "thenation.com") ~ "The Nation"
         ))) |>
  tidytable::filter(!is.na(test_source))

fwrite(filtered_linkcheck, here("data", "linkchecker", "links_pre-filtered_linkchecker.csv"))
```

```{r}
unique_parents <- filtered_test |>
  distinct(parentname)
```

```{r}
drive_upload(here("data", "linkchecker", "links_pre-filtered_linkchecker.csv"), path = "~/political-sentiment/data/links_pre-filtered_linkchecker.csv")
```

```{r}
disk_to_drive <- function(file_path, over.write = TRUE) {
  temp <- stringr::str_split(file_path, "/")[[1]][9]
  googledrive::drive_upload(file_path, path = glue::glue("~/political-sentiment/data/{temp}"), overwrite = over.write)
}

map(.x = files, .f = disk_to_drive)
```



```{r}
#| label: Jacobin Sitemap
#| eval: false

jacobin_raw <- read_rds(here("data","jacobin_unfiltered.rds"))

jacobin_exclude <- c(
  "wp-content", "format", "category", "jpg", "png", "gif",
  "com$", "\\?"
)
jacobin <-
  jacobin_raw |>
  filter(
    valid == TRUE,
    size > 1,
    is.na(infostring),
    str_detect(url, "jacobin\\.com/20"),
    str_detect(url, paste(jacobin_exclude, collapse = "|"), negate = TRUE)
  )

jacobin_mod <-
  jacobin |>
  distinct(url)

jacobin_mod <-
  jacobin_mod |>
  mutate(year = as.numeric(str_extract(url, "\\d\\d\\d\\d"))) |>
  filter(year > 2018) |>
  arrange(desc(year))

write_rds(jacobin_mod, here("data", "jacobin.rds"), "gz", compression = 9L)
```


```{r}
#| label: Brookings Sitemap
#| eval: false

# brookings_raw <- read_delim("~/brookings.csv", delim = ";", show_col_types = FALSE)
# write_rds(brookings_raw, "data/brookings_raw.rds", "gz", compression = 9L)

brookings_raw <- read_rds(here("data", "brookings_raw.rds"))

brookings_exclude <- c(
  "com$", "/experts/", "html$", "#",
  "\\?", "%", "amp/$", "feed/$"
)

brookings_include <- c(
  "edu/blog/", "edu/testimonies/", "edu/research/", "edu/book/", "pdf$"
)

brookings <-
  brookings_raw |>
  filter(
    valid == TRUE,
    size > 1,
    str_detect(url, paste(brookings_include, collapse = "|")),
    str_detect(url, paste(brookings_exclude, collapse = "|"), negate = TRUE)
  )

brookings_blog <-
  brookings |>
  filter(
    str_detect(url, brookings_include[[1]])
  ) |>
  distinct(url) |>
  arrange(url)

brookings_testimonies <-
  brookings |>
  filter(
    str_detect(url, brookings_include[[2]])
  ) |>
  distinct(url) |>
  arrange(url)

brookings_research <-
  brookings |>
  filter(
    str_detect(url, brookings_include[[3]])
  ) |>
  distinct(url) |>
  arrange(url)

brookings_book <-
  brookings |>
  filter(
    str_detect(url, brookings_include[[4]])
  ) |>
  distinct(url) |>
  arrange(url)

brookings_pdf <-
  brookings |>
  filter(
    str_detect(url, brookings_include[[5]])
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(brookings_blog, here("data", "brookings_blog.rds"), "gz", compression = 9L)
write_rds(brookings_testimonies, here("data", "brookings_testimonies.rds"), "gz", compression = 9L)
write_rds(brookings_research, here("data", "brookings_research.rds"), "gz", compression = 9L)
write_rds(brookings_book, here("data", "brookings_book.rds"), "gz", compression = 9L)
write_rds(brookings_pdf, here("data", "brookings_pdf.rds"), "gz", compression = 9L)

```


```{r}
#| label: The Nation Sitemap
#| eval: false

thenation_raw <- read_rds(here("data", "thenation_unfilted.rds"))

thenation_exclude <- c(
  "wp-", "com$", "/feed/$", "html$", "tnamp/$", "#",
  "\\?", "%"
)

thenation <-
  thenation_raw |>
  filter(
    valid == TRUE,
    size > 1,
    is.na(infostring),
    str_detect(url, "thenation\\.com/article"),
    str_detect(url, paste(thenation_exclude, collapse = "|"), negate = TRUE)
  )

thenation_mod <-
  thenation |>
  distinct(url) |>
  arrange(url)

write_rds(thenation_mod, here("data", "thenation.rds"), "gz", compression = 9L)
```


```{r}
#| label: Claremont and American Mind Data Read In
#| eval: false

features_raw <- read_delim(here("data", "americanmindfeatures.csv"), delim = ";", show_col_types = FALSE)
memos_raw <- read_delim(here("data", "americanmindmemos.csv"), delim = ";", show_col_types = FALSE)
salvos_raw <- read_delim(here("data", "americanmindsalvos.csv"), delim = ";", show_col_types = FALSE)
claremont_raw <- read_delim(here("data", "claremontreviewessays.csv"), delim = ";", show_col_types = FALSE)
```


```{r}
#| label: American Mind Features Sitemap
#| eval: false

features_exclude <- c("oembed", "twitter", "features/$", "\\.com$", "google\\.com/")

features <-
  features_raw |>
  filter(
    valid == TRUE,
    size > 1,
    str_detect(url, "americanmind\\.org/features/"),
    str_detect(url, paste(features_exclude, collapse = "|"), negate = TRUE)
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(features, here("data", "americanmindfeatures.rds"), "gz", compression = 9L)
```


```{r}
#| label: American Mind Memos Sitemap
#| eval: false

memos <-
  memos_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "org/memo/")
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(memos, here("data", "americanmindmemos.rds"), "gz", compression = 9L)
```


```{r}
#| label: American Mind Salvos Sitemap
#| eval: false

salvos <-
  salvos_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "org/salvo/")
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(salvos, here("data", "americanmindsalvos.rds"), "gz", compression = 9L)
```


```{r}
#| label: Claremont Review of Books Sitemap
#| eval: false

claremont_exclude <- c(
  "/auth", "/issue", "/article", "/subscribe", "/podcast/",
  "/donate", "/advertising/", "/archive", "/faqs/",
  "/about-us/", "/my-account/", "/contact-us/", "/digital-exclusive/",
  "/publication-committee/", "com/$", "com$", "wp-"
)


claremont <-
  claremont_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "claremontreviewofbooks\\.com"),
    str_detect(url, paste(claremont_exclude, collapse = "|"), negate = TRUE)
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(claremont, here("data", "claremontreviewessays.rds"), "gz", compression = 9L)
```


```{r}
#| label: Heritage Sitemap
#| eval: false

heritage_raw <- read_rds(here("Data", "heritage.rds"))

heritage_exclude <- c("mailto", "staff", "wp-", "\\.com", "html$", "#", "\\?", "%", "=")
heritage_include <- c("commentary", "report")

heritage <-
  heritage_raw |>
  filter(
    valid == TRUE,
    str_detect(infostring, "denied", negate = TRUE),
    str_detect(url, "www\\.heritage\\.org"),
    str_detect(url, paste(heritage_exclude, collapse = "|"), negate = TRUE),
    str_detect(url, paste(heritage_include, collapse = "|"))
  )

heritage_final <-
  heritage |>
  distinct(url) |>
  arrange(url)

heritage_commentary <-
  heritage_final |>
  filter(str_detect(url, "commentary"))

heritage_report <-
  heritage_final |>
  filter(str_detect(url, "report"))

write_rds(heritage_commentary, here("data", "heritage_commentary.rds"), "gz", compression = 9L)
write_rds(heritage_report, here("data", "heritage_report.rds"), "gz", compression = 9L)
```

```{r}
#| label: National Review Politics and Policy Sitemap
#| eval: false

nr_pol_raw <- read_delim(here("data", "nationalreviewpol.csv"), delim = ";", show_col_types = FALSE)

nr_pol <-
  nr_pol_raw |>
  filter(
    str_detect(urlname, "wp-content", negate = TRUE),
    str_detect(url, "com/20")
  ) |>
  transmute(url) |>
  distinct(url) |>
  arrange(url)

write_rds(nr_pol, here("data", "nationalreview_pol_policy.rds"), "gz", compression = 9L)
```

```{r}
#| label: National Review Courts Sitemap
#| eval: false

nr_law_courts_raw <- read_delim(here("data", "nationalreviewlawcourts.csv"), delim = ";", show_col_types = FALSE)

nr_law_courts <-
  nr_law_courts_raw |>
  filter(
    str_detect(urlname, "wp-content", negate = TRUE),
    str_detect(url, "com/20")
  ) |>
  transmute(url) |>
  distinct(url) |>
  arrange(url)

write_rds(nr_law_courts, here("data", "nationalreview_law_courts.rds"), "gz", compression = 9L)
```